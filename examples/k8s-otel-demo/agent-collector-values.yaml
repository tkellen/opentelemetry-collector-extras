mode: daemonset

fullnameOverride: otelcol

image:
  repository: puckpuck/otelcol-custom
  tag: latest
  pullPolicy: Always

command:
  name: otelcol-custom

# Required to use the kubeletstats cpu/memory utilization metrics
clusterRole:
  create: true
  rules:
    - apiGroups: 
        - ""
      resources:
        - nodes/proxy
      verbs:
        - get

extraEnvs:
  - name: HONEYCOMB_API_KEY
    valueFrom:
      secretKeyRef:
        name: honeycomb
        key: api-key

presets:
  # enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
  kubernetesAttributes:
    enabled: true
    extractAllPodLabels: true
    extractAllPodAnnotations: true
  # enables the kubeletstatsreceiver and adds it to the metrics pipelines
  kubeletMetrics:
    enabled: true

config:
  receivers:
    jaeger: null
    zipkin: null
    kubeletstats:
      metric_groups:
        - node
        - pod
      metrics:
        k8s.node.uptime:
          enabled: true
        k8s.pod.uptime:
          enabled: true
        k8s.pod.cpu_limit_utilization:
          enabled: true
        k8s.pod.cpu_request_utilization:
          enabled: true
        k8s.pod.memory_limit_utilization:
          enabled: true
        k8s.pod.memory_request_utilization:
          enabled: true

  exporters:
    otlp:
      endpoint: "api.honeycomb.io:443"
      headers:
        "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
    otlp/kafka:
      endpoint: "otelcol-cluster:4317"
      tls:
        insecure: true
    otlp/k8s-metrics:
      endpoint: "api.honeycomb.io:443"
      headers:
        "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
        "x-honeycomb-dataset": "k8s-metrics"
    otlp/k8s-logs:
      endpoint: "api.honeycomb.io:443"
      headers:
        "x-honeycomb-team": "${env:HONEYCOMB_API_KEY}"
        "x-honeycomb-dataset": "k8s-logs"

  processors:
    filter/no-kafka:
      error_mode: ignore
      traces:
        span:
          - attributes["messaging.system"] == "kafka"
    filter/only-kafka:
      error_mode: ignore
      traces:
        span:
          - attributes["messaging.system"] != "kafka"

    metricsasattributes:
      metrics_groups:
        - name: k8s-pod
          target_selectors:
            spans:
              - attribute_type: resource
                name: k8s.pod.name
              - attribute_type: resource
                name: k8s.namespace.name
          metrics_selectors:
            - attribute_type: resource
              name: k8s.pod.name
            - attribute_type: resource
              name: k8s.namespace.name
          metrics_to_add:
            - instrumentation_scope: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kubeletstatsreceiver
              metrics:
                - name: "k8s.pod.*"

        - name: k8s-node
          target_selectors:
            spans:
              - attribute_type: resource
                name: k8s.node.name
          metrics_selectors:
            - attribute_type: resource
              name: k8s.node.name
          metrics_to_add:
            - instrumentation_scope: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/kubeletstatsreceiver
              metrics:
                - name: "k8s.node.*"

  service:
#    telemetry:
#      logs:
#        level: debug
    pipelines:
      traces:
        receivers: [otlp]
        processors: [memory_limiter, filter/no-kafka, k8sattributes, metricsasattributes, batch]
        exporters: [otlp]
      traces/kafka:
        receivers: [otlp]
        processors: [memory_limiter, filter/only-kafka, k8sattributes, metricsasattributes, batch]
        exporters: [otlp/kafka]
      metrics:
        receivers: [otlp, kubeletstats]
        processors: [memory_limiter, k8sattributes, metricsasattributes, batch]
        exporters: [otlp/k8s-metrics]
      logs:
        exporters: [otlp/k8s-logs]

ports:
  jaeger-compact:
    enabled: false
  jaeger-thrift:
    enabled: false
  jaeger-grpc:
    enabled: false
  zipkin:
    enabled: false